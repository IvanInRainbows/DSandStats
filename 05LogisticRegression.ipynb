{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install vaderSentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdCN0M3NIcnc",
        "outputId": "fb4b6d60-cd47-44f2-f97c-1ca7d1b78a1b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.10/dist-packages (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vaderSentiment) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2024.7.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TlYBfNEo9Fp9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2ab2a73-73fe-437c-84b3-e6250f22c1ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "import pandas as pd\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "import math\n",
        "import csv\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "nltk.download(\"punkt\")\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "sentiment_analyzer = SentimentIntensityAnalyzer()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Logistic Regression\n",
        "\n",
        "Logistic regression learns from a training set, a vector of weights (one for each feature) and a bias.\n",
        "\n",
        "To make a decission on a test (after training the model) the classifier multiplies each weight (w_i) by its feature (x_i), sums up the weighted features and adds the bias (also called intercept)\n",
        "\n",
        "    z = x*w + b\n",
        "\n",
        "note that **x** and **w** are vectors.\n",
        "\n",
        "To create a probability we must pass *z* through the sigmoid function\n",
        "\n",
        "    sigmoid(z) = 1/(1 + e^-z)\n",
        "    \n",
        "e^x is equal to the exponential of *-z*. The result is a number between 1 and 0, but we need to make sure that *sigmoid(z) + (1-sigmoid(z))* equals 0, meaning that the sum of all the probabilities is 1. A propierty of the sigmoid function is that 1-sigmoid(x) = sigmoid(-x)."
      ],
      "metadata": {
        "id": "rhhslINV9Kgf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Logistic regression Model"
      ],
      "metadata": {
        "id": "cAU5Vh-Ek0Op"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Classes and functions"
      ],
      "metadata": {
        "id": "Ak5RWdXEk6QT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LogRegModel(nn.Module):\n",
        "  def __init__(self, nfeatures, *args, **kwargs) -> None:\n",
        "    super().__init__(*args, **kwargs)\n",
        "    self.weights = nn.Parameter(torch.randn(nfeatures, requires_grad=True, dtype=torch.float64))\n",
        "    self.bias = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float64))\n",
        "\n",
        "  def forward(self, x: torch.Tensor)->torch.Tensor:\n",
        "    return sigmoid(torch.sum(self.weights * x +self.bias, 1))\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1/(1+ math.e**-x)\n",
        "\n",
        "def computeFeatures(x : np.ndarray):\n",
        "  out = torch.zeros(len(x), 5)\n",
        "  for i in range(len(x)):\n",
        "    out[i][0] = sentiment_analyzer.polarity_scores(x[i])[\"pos\"]\n",
        "    out[i][1] = sentiment_analyzer.polarity_scores(x[i])[\"neg\"]\n",
        "    out[i][2] = 1 if \" no \" in x[i] else 0\n",
        "    out[i][3] = len(re.findall(\"[\\s.,](me|i|mine|you|your|my)[\\s.,]\", x[i]))+len(re.findall(\"^(me|i|mine|you|your)\", x[i])) + len(re.findall(\"(me|i|mine|you|your)$\", x[i]))\n",
        "    out[i][4] = 1 if \"!\" in x[i] else 0\n",
        "  return out\n",
        "\n",
        "def computeSent(y):\n",
        "  out = torch.zeros(len(y))\n",
        "  for i in range(len(y)):\n",
        "    if y[i] == \"positive\":\n",
        "      out[i] = 1\n",
        "  return out\n",
        "\n",
        "def comparePredict(prediction, testdata):\n",
        "    \"\"\"\n",
        "    Compares the predicted system output data to the 'gold standard' data.\n",
        "    Returns a dictionary with the recall, precision, and accuracy inside.\n",
        "    Dtypes should match\n",
        "    \"\"\"\n",
        "    tp = 1\n",
        "    tn = 1\n",
        "    fp = 1\n",
        "    fn = 1\n",
        "\n",
        "    for i in range(len(prediction)):\n",
        "      if prediction[i] == testdata[i]:\n",
        "        if prediction[i] == 1.0:\n",
        "          tp+=1\n",
        "        else:\n",
        "          tn+=1\n",
        "      else:\n",
        "        if prediction[i] == 1.0:\n",
        "          fp+=1\n",
        "        else:\n",
        "          fn+=1\n",
        "    precision = tp/(tp+fp)\n",
        "    recall = tp/(tp+fn)\n",
        "    acc = (tp+tn)/(tp+tn+fp+fn)\n",
        "    print(f\"\"\"\n",
        "          True positives = {tp-1}\n",
        "          True negatives = {tn-1}\n",
        "          False positives = {fp-1}\n",
        "          False negatives = {fn-1}\n",
        "          Precision = {precision}\n",
        "          Recall = {recall}\n",
        "          Accuracy = {(acc)*100}%\n",
        "    \"\"\")\n",
        "    return {\"precision\" : precision, \"recall\" : recall, \"accuracy\" : acc}"
      ],
      "metadata": {
        "id": "3fq2NC-iCg6N"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data preparation"
      ],
      "metadata": {
        "id": "KB3zqbb5k-N8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/IMDB.csv\", index_col=False, header=0, encoding=\"UTF-8\", on_bad_lines=\"skip\", engine=\"python\")\n",
        "\n",
        "for i in range(len(data)):\n",
        "  data[\"review\"][i] = re.sub(\"<br />\", \" \", data[\"review\"][i])\n",
        "  data[\"review\"][i] = re.sub(\"\\\"\", \"'\", data[\"review\"][i])\n"
      ],
      "metadata": {
        "id": "M9Qw96AcCHPZ"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = np.array([i.lower() for i in data[\"review\"].to_numpy()])\n",
        "sent = np.array([float(0) if i == \"negative\" else float(1) for i in data[\"sentiment\"].to_numpy()])"
      ],
      "metadata": {
        "id": "k8PcFHluXLP8"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = computeFeatures(reviews[:20000])\n",
        "y = torch.from_numpy(sent[:20000])"
      ],
      "metadata": {
        "id": "B2cauL_5kq6W"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_point = int(0.8 * len(x))\n",
        "x_train, y_train = x[0:split_point], y[0:split_point]\n",
        "x_test, y_test = x[split_point:], y[split_point:]\n",
        "len(x_train), len(y_train), len(y_test), len(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXkQI0x3kiS1",
        "outputId": "55721a2d-e596-4412-8e15-6b020dce3cca"
      },
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16000, 16000, 4000, 4000)"
            ]
          },
          "metadata": {},
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model"
      ],
      "metadata": {
        "id": "tBqH2gUqlGZ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(43)\n",
        "modelLogReg = LogRegModel(5)\n",
        "modelLogReg.state_dict()\n",
        "loss_fn = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(params=modelLogReg.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "o6hzuIQGFA74"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training"
      ],
      "metadata": {
        "id": "RBT860ISlLwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10000 #iterations over data\n",
        "\n",
        "for i in range(epochs):\n",
        "  modelLogReg.train()\n",
        "  #1. Forward\n",
        "  y_prediction = modelLogReg(x_train)\n",
        "  #2. cost function\n",
        "  loss = loss_fn(y_prediction, y_train)\n",
        "  #3. Optimizer 0grad\n",
        "  optimizer.zero_grad()\n",
        "  #4. Backpropagation\n",
        "  loss.backward()\n",
        "  #5. Optimization (SGD)\n",
        "  optimizer.step()\n",
        "\n",
        "modelLogReg.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdZlByOSlPBr",
        "outputId": "ac82d10e-e302-4684-e8b0-2b7b49f5ddaf"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weights',\n",
              "              tensor([ 7.0218, -8.0628, -0.3910, -0.0108, -0.0546], dtype=torch.float64)),\n",
              "             ('bias', tensor([-0.0106], dtype=torch.float64))])"
            ]
          },
          "metadata": {},
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Testing"
      ],
      "metadata": {
        "id": "YESrzvGdlPdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelLogReg.eval()\n",
        "test_pred = modelLogReg(x_test)\n",
        "comparePredict(torch.round(test_pred), y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prtpgVFSmXcz",
        "outputId": "9c74a351-c488-445f-bd81-c02c086eef8a"
      },
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "          True positives = 1412\n",
            "          True negatives = 1482\n",
            "          False positives = 511\n",
            "          False negatives = 595\n",
            "          Precision = 0.734025974025974\n",
            "          Recall = 0.7033349925335988\n",
            "          Accuracy = 72.32767232767233%\n",
            "    \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'precision': 0.734025974025974,\n",
              " 'recall': 0.7033349925335988,\n",
              " 'accuracy': 0.7232767232767233}"
            ]
          },
          "metadata": {},
          "execution_count": 224
        }
      ]
    }
  ]
}